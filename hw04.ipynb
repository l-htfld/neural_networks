{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Input\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "FMW1ZXcTglM8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(image_dir, labels_file):\n",
        "    data = pd.read_excel(labels_file)\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for img_path in glob.glob(os.path.join(image_dir, \"*.png\")):\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('L')\n",
        "            img = img.resize((200, 50))\n",
        "            img_array = np.array(img) / 255.0\n",
        "            img_num = int(os.path.basename(img_path).split('.')[0])\n",
        "            answer = data.iloc[img_num-1]['Answer']\n",
        "            images.append(img_array)\n",
        "            labels.append(float(answer))\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {img_path}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "fZ6ePTJpgnwL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "\n",
        "    # Входной слой ожидает изображения размером 50x200 пикселей с 1 черно-белым каналом\n",
        "    inputs = Input(shape=(50, 200, 1))\n",
        "\n",
        "    # Первый сверточный блок\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same')(inputs) # Применяем 64 фильтра размером для обнаружения базовых признаков (грани)\n",
        "    x = layers.BatchNormalization()(x) # Нормализуем для стабильности\n",
        "    x = layers.Activation('relu')(x) # Функция активации\n",
        "    x = layers.MaxPooling2D((2, 2))(x) # Уменьшаем пространственные размеры, сохраняя самые сильные признаки\n",
        "\n",
        "    # В остальных блоках плюс-минус то же самое\n",
        "\n",
        "    # Второй сверточный блок\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Третий сверточный блок\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Flatten()(x) # Преобразование 3д в 1д для полносвязных слоев\n",
        "    x = layers.Dense(512, activation='relu')(x) # Первый полносвязный слой\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x) # Дропаут, чтобы не было переобучения\n",
        "    x = layers.Dense(256, activation='relu')(x) # Второй полносвязный слой\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1)(x) # Выходной слой\n",
        "\n",
        "    return models.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "fUmUb2rrg58s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(image_dir, labels_file):\n",
        "    X, y = load_data(image_dir, labels_file)\n",
        "    X = X.reshape(-1, 50, 200, 1)\n",
        "\n",
        "    split = int(0.8 * len(X))\n",
        "    X_train, X_test = X[:split], X[split:]\n",
        "    y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "    # Аугментация выборки\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=5,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        shear_range=0.1\n",
        "    )\n",
        "\n",
        "    model = create_model()\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                 loss='mse',\n",
        "                 metrics=['mae'])\n",
        "\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6\n",
        "    )\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        datagen.flow(X_train, y_train, batch_size=32),\n",
        "        epochs=50,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=[reduce_lr, early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\nTest MAE: {test_mae:.2f}\")\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "dZsqdAsZg8BD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/drive/MyDrive/repos/Handwritten_equations_images\"\n",
        "labels_file = \"/content/Maths_eqations_handwritten.xlsx\"\n",
        "model, history = train_model(image_dir, labels_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSgRDb4azyQl",
        "outputId": "fb28e973-5e03-4d8e-e8fd-3b5797f87cd4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping /content/drive/MyDrive/repos/Handwritten_equations_images/60.png: single positional indexer is out-of-bounds\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - loss: 28612.9707 - mae: 72.2758 - val_loss: 844.9903 - val_mae: 20.7718 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4s/step - loss: 17745.5645 - mae: 57.9718 - val_loss: 844.8584 - val_mae: 20.7673 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - loss: 22588.9609 - mae: 67.4229 - val_loss: 842.5577 - val_mae: 20.7110 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - loss: 20620.4824 - mae: 62.0896 - val_loss: 838.7894 - val_mae: 20.6199 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - loss: 20947.8223 - mae: 69.9201 - val_loss: 834.8255 - val_mae: 20.5234 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - loss: 20680.1016 - mae: 68.3666 - val_loss: 830.5815 - val_mae: 20.4197 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - loss: 16124.6348 - mae: 57.8570 - val_loss: 826.6328 - val_mae: 20.3227 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - loss: 16957.5195 - mae: 59.9983 - val_loss: 823.1536 - val_mae: 20.2369 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4s/step - loss: 32193.0820 - mae: 87.2777 - val_loss: 820.8141 - val_mae: 20.1789 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - loss: 24883.1191 - mae: 67.7279 - val_loss: 819.4233 - val_mae: 20.1438 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 20030.7227 - mae: 62.0924 - val_loss: 817.2138 - val_mae: 20.0885 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4s/step - loss: 16713.5195 - mae: 58.4108 - val_loss: 813.9925 - val_mae: 20.0074 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - loss: 17959.8945 - mae: 58.6955 - val_loss: 811.3553 - val_mae: 19.9403 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 21973.2246 - mae: 66.5967 - val_loss: 808.1897 - val_mae: 19.8595 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - loss: 13591.2129 - mae: 51.0997 - val_loss: 804.9260 - val_mae: 19.7768 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - loss: 17378.1836 - mae: 62.9235 - val_loss: 801.5982 - val_mae: 19.6929 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - loss: 14903.5645 - mae: 53.9137 - val_loss: 799.0649 - val_mae: 19.6285 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5s/step - loss: 17098.3516 - mae: 57.6327 - val_loss: 797.3148 - val_mae: 19.5839 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - loss: 27499.3613 - mae: 77.0132 - val_loss: 796.1008 - val_mae: 19.5525 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - loss: 16988.1074 - mae: 60.5392 - val_loss: 794.5229 - val_mae: 19.5117 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step - loss: 13905.5625 - mae: 53.4754 - val_loss: 791.6166 - val_mae: 19.4370 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - loss: 13311.3994 - mae: 49.9653 - val_loss: 788.7675 - val_mae: 19.3637 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - loss: 21662.3379 - mae: 66.3030 - val_loss: 785.9662 - val_mae: 19.2911 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 17124.9082 - mae: 62.1970 - val_loss: 782.0264 - val_mae: 19.1887 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 13635.7812 - mae: 52.4133 - val_loss: 779.3511 - val_mae: 19.1183 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5s/step - loss: 13578.9014 - mae: 48.9477 - val_loss: 775.5703 - val_mae: 19.0188 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - loss: 13653.8105 - mae: 51.6918 - val_loss: 772.3235 - val_mae: 18.9329 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - loss: 15174.5420 - mae: 56.4963 - val_loss: 770.2343 - val_mae: 18.8770 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - loss: 13825.9531 - mae: 53.9190 - val_loss: 768.3702 - val_mae: 18.8259 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - loss: 22078.5156 - mae: 68.5993 - val_loss: 766.1478 - val_mae: 18.7650 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - loss: 20141.9785 - mae: 62.2706 - val_loss: 764.5106 - val_mae: 18.7202 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4s/step - loss: 24535.3555 - mae: 71.2271 - val_loss: 762.8782 - val_mae: 18.6758 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - loss: 20098.7539 - mae: 66.7771 - val_loss: 760.6639 - val_mae: 18.6166 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4s/step - loss: 28413.3809 - mae: 78.6826 - val_loss: 758.2678 - val_mae: 18.5522 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 15340.0674 - mae: 57.9782 - val_loss: 757.0281 - val_mae: 18.5189 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - loss: 20033.8203 - mae: 65.0432 - val_loss: 754.9253 - val_mae: 18.4618 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 16439.3828 - mae: 59.3978 - val_loss: 752.6083 - val_mae: 18.3986 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 21647.5879 - mae: 65.8871 - val_loss: 751.7693 - val_mae: 18.3753 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step - loss: 13222.9619 - mae: 50.8141 - val_loss: 748.9893 - val_mae: 18.2984 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5s/step - loss: 16802.9668 - mae: 58.5359 - val_loss: 745.9665 - val_mae: 18.2154 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 15248.8936 - mae: 58.8364 - val_loss: 743.4438 - val_mae: 18.1451 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - loss: 17430.3594 - mae: 64.7180 - val_loss: 741.5783 - val_mae: 18.0929 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 20576.2539 - mae: 65.9135 - val_loss: 740.0847 - val_mae: 18.0519 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - loss: 16721.6836 - mae: 61.9784 - val_loss: 736.6976 - val_mae: 17.9579 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - loss: 16687.9551 - mae: 59.3563 - val_loss: 733.5263 - val_mae: 17.8701 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5s/step - loss: 14239.7363 - mae: 58.2969 - val_loss: 730.6317 - val_mae: 17.7889 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 19939.2363 - mae: 63.0614 - val_loss: 727.2936 - val_mae: 17.6981 - learning_rate: 1.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 20737.4336 - mae: 66.2812 - val_loss: 725.1483 - val_mae: 17.6468 - learning_rate: 1.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4s/step - loss: 13665.6152 - mae: 55.7513 - val_loss: 723.0059 - val_mae: 17.5954 - learning_rate: 1.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 20176.4453 - mae: 64.9013 - val_loss: 720.1069 - val_mae: 17.5269 - learning_rate: 1.0000e-04\n",
            "\n",
            "Test MAE: 17.53\n"
          ]
        }
      ]
    }
  ]
}